from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import google.generativeai as genai
import json
import os
from dotenv import load_dotenv
from retrieval_bidirectional import load_assets, load_models, search_bidirectional, detect_query_type

# Load environment variables
load_dotenv()

app = FastAPI(title="Health Chatbot API", version="1.0.0")

# Enable CORS for frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =========================
# Config constants
# =========================
EMBED_MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
RERANKER_NAME = "cross-encoder/ms-marco-MiniLM-L-6-v2"
INDEX_PATH = "faiss.index"
DOCUMENTS_PATH = "documents.pkl"

# =========================
# Global loaded objects
# =========================
embed_model = None
reranker = None
faiss_index = None
documents = None
disease_map = None  # Added for bidirectional support

# =========================
# Configure Gemini
# =========================
API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyB9N-bcCq8NADKKfA6Hena90txX790ewjU")
genai.configure(api_key=API_KEY)
model = genai.GenerativeModel("gemini-2.5-flash")

if not API_KEY or API_KEY == "your_api_key_here":
    print("‚ö†Ô∏è  WARNING: Please set GEMINI_API_KEY in .env file")
    print("   Get your API key at: https://aistudio.google.com/apikey")


# =========================
# Request/Response Models
# =========================
class ChatRequest(BaseModel):
    message: str


class ChatResponse(BaseModel):
    reply: str
    evidence: list


# =========================
# Startup: Load models once
# =========================
@app.on_event("startup")
async def startup_event():
    global embed_model, reranker, faiss_index, documents, disease_map
    print("üöÄ Loading models and indexes...")
    _, documents, faiss_index, disease_map = load_assets()
    embed_model, reranker = load_models()
    print("‚úÖ Models loaded successfully!")


# =========================
# Helper functions
# =========================
def detect_query_intent(user_message: str) -> str:
    """Detect if user is asking symptoms->disease or disease->symptoms"""
    return detect_query_type(user_message)


def extract_symptoms_llm(user_message: str) -> list:
    """Extract symptoms from user message using Gemini"""
    prompt = f"""
    B·∫°n l√† tr·ª£ l√Ω y t·∫ø. H√£y ƒë·ªçc c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng v√† li·ªát k√™ c√°c tri·ªáu ch·ª©ng s·ª©c kh·ªèe h·ªç ƒëang g·∫∑p.
    Ch·ªâ li·ªát k√™ tri·ªáu ch·ª©ng, m·ªói d√≤ng m·ªôt tri·ªáu ch·ª©ng, ng·∫Øn g·ªçn.
    
    C√¢u h·ªèi: {user_message}
    
    C√°c tri·ªáu ch·ª©ng:
    """
    
    response = model.generate_content(prompt)
    symptoms = [s.strip() for s in response.text.strip().split('\n') if s.strip()]
    return symptoms


def extract_disease_llm(user_message: str) -> str:
    """Extract disease name from user message using Gemini"""
    prompt = f"""
    B·∫°n l√† tr·ª£ l√Ω y t·∫ø. H√£y ƒë·ªçc c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng v√† tr√≠ch xu·∫•t t√™n b·ªánh h·ªç ƒëang h·ªèi.
    Ch·ªâ tr·∫£ l·ªùi t√™n b·ªánh, ng·∫Øn g·ªçn, kh√¥ng gi·∫£i th√≠ch.
    
    C√¢u h·ªèi: {user_message}
    
    T√™n b·ªánh:
    """
    
    response = model.generate_content(prompt)
    return response.text.strip()


def retrieve_bidirectional(query_text: str, query_type: str) -> list:
    """Retrieve results using bidirectional system"""
    results = search_bidirectional(
        query_text, 
        embed_model, 
        reranker, 
        faiss_index, 
        documents, 
        query_type=query_type,
        top_k=5
    )
    return results


def generate_medical_answer(user_message: str, query_type: str, retrieved_info: list, extracted_info: any) -> str:
    """Generate final answer using Gemini with retrieved context"""
    
    if query_type == "symptoms_to_disease":
        evidence_text = "\n".join([
            f"- {d['disease']}"
            for d in retrieved_info[:3]
        ])
        
        prompt = f"""
        B·∫°n l√† tr·ª£ l√Ω s·ª©c kh·ªèe th√¢n thi·ªán, n√≥i chuy·ªán t·ª± nhi√™n nh∆∞ m·ªôt ng∆∞·ªùi b·∫°n quan t√¢m.
        
        Ng∆∞·ªùi d√πng h·ªèi: {user_message}
        
        Tri·ªáu ch·ª©ng: {', '.join(extracted_info)}
        
        Theo d·ªØ li·ªáu y t·∫ø, c√°c b·ªánh c√≥ th·ªÉ li√™n quan:
        {evidence_text}
        
        H√£y tr·∫£ l·ªùi theo phong c√°ch:
        - N√≥i chuy·ªán t·ª± nhi√™n, th√¢n thi·ªán nh∆∞ ƒëang t∆∞ v·∫•n tr·ª±c ti·∫øp
        - D√πng "m√¨nh", "b·∫°n" thay v√¨ "t√¥i", "b·ªánh nh√¢n"
        - Gi·∫£i th√≠ch ƒë∆°n gi·∫£n, d·ªÖ hi·ªÉu
        - Th·ªÉ hi·ªán s·ª± quan t√¢m ch√¢n th√†nh
        - Nh·∫Øc nh·ªü n√™n ƒëi kh√°m b√°c sƒ© ƒë·ªÉ ch·∫©n ƒëo√°n ch√≠nh x√°c
        - Kh√¥ng li·ªát k√™ qu√° nhi·ªÅu b·ªánh, ch·ªâ t·∫≠p trung v√†o 1-2 kh·∫£ nƒÉng ch√≠nh
        - ƒê·ªô d√†i v·ª´a ph·∫£i (3-5 c√¢u)
        """
    else:  # disease_to_symptoms
        evidence_text = "\n".join([
            f"- {s['symptom']}"
            for s in retrieved_info[:5]
        ])
        
        prompt = f"""
        B·∫°n l√† tr·ª£ l√Ω s·ª©c kh·ªèe th√¢n thi·ªán, n√≥i chuy·ªán t·ª± nhi√™n nh∆∞ m·ªôt ng∆∞·ªùi b·∫°n quan t√¢m.
        
        Ng∆∞·ªùi d√πng h·ªèi v·ªÅ b·ªánh: {extracted_info}
        C√¢u h·ªèi g·ªëc: {user_message}
        
        C√°c tri·ªáu ch·ª©ng ph·ªï bi·∫øn c·ªßa b·ªánh {extracted_info}:
        {evidence_text}
        
        H√£y tr·∫£ l·ªùi theo phong c√°ch:
        - N√≥i chuy·ªán t·ª± nhi√™n, th√¢n thi·ªán
        - Gi·∫£i th√≠ch c√°c tri·ªáu ch·ª©ng ƒë∆°n gi·∫£n, d·ªÖ hi·ªÉu
        - Nh√≥m c√°c tri·ªáu ch·ª©ng li√™n quan l·∫°i v·ªõi nhau
        - Th·ªÉ hi·ªán s·ª± quan t√¢m
        - Khuy√™n n√™n ƒëi kh√°m n·∫øu c√≥ c√°c tri·ªáu ch·ª©ng n√†y
        - ƒê·ªô d√†i v·ª´a ph·∫£i (4-6 c√¢u)
        """
    
    response = model.generate_content(prompt)
    return response.text


# =========================
# API Endpoints
# =========================
@app.get("/")
async def root():
    return {
        "message": "Health Chatbot API",
        "status": "running",
        "endpoints": {
            "POST /chat": "Send a health query",
            "GET /health": "Check API health"
        }
    }


@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "models_loaded": embed_model is not None and reranker is not None
    }


@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """Main chat endpoint with bidirectional support"""
    try:
        user_message = request.message.strip()
        
        if not user_message:
            raise HTTPException(status_code=400, detail="Message cannot be empty")
        
        # Detect query type
        query_type = detect_query_intent(user_message)
        print(f"üîç Query type: {query_type}")
        
        if query_type == "symptoms_to_disease":
            # Extract symptoms
            symptoms = extract_symptoms_llm(user_message)
            print(f"üìã Extracted symptoms: {symptoms}")
            
            if len(symptoms) < 1:
                return ChatResponse(
                    reply="Ch√†o b·∫°n! M√¨nh mu·ªën h·ªó tr·ª£ b·∫°n nh∆∞ng c·∫ßn bi·∫øt th√™m v·ªÅ tri·ªáu ch·ª©ng b·∫°n ƒëang g·∫∑p ph·∫£i. B·∫°n c√≥ th·ªÉ k·ªÉ c·ª• th·ªÉ h∆°n v·ªÅ c·∫£m gi√°c kh√≥ ch·ªãu hay nh·ªØng d·∫•u hi·ªáu b·∫•t th∆∞·ªùng n√†o kh√¥ng?",
                    evidence=[]
                )
            
            # Retrieve diseases
            symptoms_query = " ".join(symptoms)
            results = retrieve_bidirectional(symptoms_query, "symptoms_to_disease")
            print(f"üîç Found {len(results)} diseases")
            
            # Generate answer
            reply = generate_medical_answer(user_message, query_type, results, symptoms)
            
            return ChatResponse(
                reply=reply,
                evidence=results[:5]
            )
        
        else:  # disease_to_symptoms
            # Extract disease name
            disease_name = extract_disease_llm(user_message)
            print(f"üè• Extracted disease: {disease_name}")
            
            if not disease_name:
                return ChatResponse(
                    reply="B·∫°n mu·ªën h·ªèi v·ªÅ tri·ªáu ch·ª©ng c·ªßa b·ªánh n√†o? H√£y cho m√¨nh bi·∫øt t√™n b·ªánh ƒë·ªÉ m√¨nh c√≥ th·ªÉ gi√∫p b·∫°n nh√©!",
                    evidence=[]
                )
            
            # Retrieve symptoms
            results = retrieve_bidirectional(disease_name, "disease_to_symptoms")
            print(f"üîç Found {len(results)} symptoms")
            
            # Generate answer
            reply = generate_medical_answer(user_message, query_type, results, disease_name)
            
            return ChatResponse(
                reply=reply,
                evidence=results[:5]
            )
    
    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# =========================
# Run server
# =========================
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, port=8000)
