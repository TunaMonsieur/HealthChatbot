"""
Bidirectional Retrieval System for Health Chatbot
Support: Symptoms â†’ Disease AND Disease â†’ Symptoms
"""

import numpy as np
import pickle
import faiss
import torch
import pandas as pd
import re
from sentence_transformers import SentenceTransformer, CrossEncoder
from typing import List, Dict, Tuple
from collections import defaultdict

# =========================
# CONFIG
# =========================
EMBED_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
RERANK_MODEL = "cross-encoder/ms-marco-MiniLM-L-6-v2"

EMBEDDINGS_PATH = "embeddings.npy"
DOCS_PATH = "documents.pkl"
FAISS_PATH = "faiss.index"
CSV_PATH = "ViMedical_Disease.csv"

TOP_K = 10


# =========================
# Extract symptoms from questions
# =========================
def extract_symptoms_from_question(question: str) -> List[str]:
    """
    TrÃ­ch xuáº¥t triá»‡u chá»©ng tá»« cÃ¢u há»i
    """
    # Remove common question patterns
    text = re.sub(r'TÃ´i cÃ³ thá»ƒ Ä‘ang bá»‹ bá»‡nh gÃ¬\??', '', question, flags=re.IGNORECASE)
    text = re.sub(r'TÃ´i Ä‘ang bá»‹ bá»‡nh gÃ¬\??', '', text, flags=re.IGNORECASE)
    text = re.sub(r'lÃ  bá»‡nh gÃ¬\??', '', text, flags=re.IGNORECASE)
    text = re.sub(r'cÃ³ pháº£i lÃ \s+\w+\s+khÃ´ng\??', '', text, flags=re.IGNORECASE)
    
    # Extract symptoms patterns
    patterns = [
        r'triá»‡u chá»©ng nhÆ° ([^.?]+)',
        r'cÃ¡c triá»‡u chá»©ng nhÆ° ([^.?]+)',
        r'tÃ´i (?:hiá»‡n Ä‘ang cÃ³|Ä‘ang cÃ³|Ä‘ang cáº£m tháº¥y|cáº£m tháº¥y|bá»‹|hay) ([^.?]+)',
        r'tÃ´i Ä‘ang ([^.?]+)',
    ]
    
    symptoms = []
    for pattern in patterns:
        matches = re.findall(pattern, text, flags=re.IGNORECASE)
        symptoms.extend(matches)
    
    # Clean and split
    all_symptoms = []
    for s in symptoms:
        s = s.strip()
        # Split by comma or "vÃ "
        parts = re.split(r'[,;]|\s+vÃ \s+', s)
        all_symptoms.extend([p.strip() for p in parts if p.strip()])
    
    return list(set(all_symptoms))  # Remove duplicates


# =========================
# Build Disease â†’ Symptoms mapping
# =========================
def build_disease_symptom_mapping(csv_path: str = CSV_PATH) -> Dict[str, Dict]:
    """
    Táº¡o mapping tá»« bá»‡nh sang triá»‡u chá»©ng
    Returns: {disease_name: {"symptoms": [...], "sample_questions": [...]}}
    """
    df = pd.read_csv(csv_path)
    df = df.dropna()
    
    disease_map = defaultdict(lambda: {"symptoms": set(), "questions": []})
    
    for _, row in df.iterrows():
        disease = row["Disease"]
        question = row["Question"]
        
        # Extract symptoms tá»« question
        symptoms = extract_symptoms_from_question(question)
        
        disease_map[disease]["symptoms"].update(symptoms)
        disease_map[disease]["questions"].append(question)
    
    # Convert sets to lists and limit questions
    result = {}
    for disease, data in disease_map.items():
        result[disease] = {
            "symptoms": list(data["symptoms"]),
            "sample_questions": data["questions"][:5],  # Keep first 5 as examples
            "symptom_count": len(data["symptoms"]),
            "question_count": len(data["questions"])
        }
    
    return result


# =========================
# Load assets
# =========================
def load_assets():
    embeddings = np.load(EMBEDDINGS_PATH)

    with open(DOCS_PATH, "rb") as f:
        documents = pickle.load(f)

    index = faiss.read_index(FAISS_PATH)
    
    # Build disease-symptom mapping
    disease_map = build_disease_symptom_mapping(CSV_PATH)
    
    return embeddings, documents, index, disease_map


# =========================
# Load models
# =========================
def load_models():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ”¥ Device: {device}")

    embed_model = SentenceTransformer(EMBED_MODEL, device=device)
    reranker = CrossEncoder(RERANK_MODEL, device=device)

    return embed_model, reranker


# =========================
# Query direction detection
# =========================
def detect_query_direction(query: str) -> str:
    """
    PhÃ¡t hiá»‡n hÆ°á»›ng truy váº¥n: symptomsâ†’disease hoáº·c diseaseâ†’symptoms
    Returns: "symptom_to_disease" hoáº·c "disease_to_symptom"
    """
    query_lower = query.lower()
    
    # Patterns cho disease â†’ symptoms
    disease_to_symptom_patterns = [
        r'triá»‡u chá»©ng cá»§a\s+(\w+)',
        r'(\w+)\s+cÃ³ triá»‡u chá»©ng gÃ¬',
        r'bá»‡nh\s+(\w+)\s+(?:cÃ³|biá»ƒu hiá»‡n|triá»‡u chá»©ng)',
        r'cÃ¡c triá»‡u chá»©ng cá»§a bá»‡nh\s+(\w+)',
        r'(\w+)\s+biá»ƒu hiá»‡n nhÆ° tháº¿ nÃ o',
        r'dáº¥u hiá»‡u cá»§a\s+(\w+)',
        r'nháº­n biáº¿t\s+(\w+)',
    ]
    
    for pattern in disease_to_symptom_patterns:
        if re.search(pattern, query_lower):
            return "disease_to_symptom"
    
    # Default: symptom â†’ disease
    return "symptom_to_disease"


def detect_query_type(query: str) -> str:
    """
    Alias for detect_query_direction, returns standardized format
    Returns: "symptoms_to_disease" or "disease_to_symptoms"
    """
    direction = detect_query_direction(query)
    # Normalize to match deploy.py expected format
    if direction == "disease_to_symptom":
        return "disease_to_symptoms"
    else:
        return "symptoms_to_disease"


# =========================
# Search: Symptoms â†’ Disease (Original)
# =========================
def search_disease_from_symptoms(query: str, embed_model, reranker, index, documents, top_k=TOP_K):
    """
    TÃ¬m bá»‡nh tá»« triá»‡u chá»©ng (hÆ°á»›ng ban Ä‘áº§u)
    """
    # FAISS retrieval
    q_emb = embed_model.encode(
        [query],
        normalize_embeddings=True,
        convert_to_numpy=True
    ).astype("float32")

    _, indices = index.search(q_emb, top_k)
    candidates = [documents[idx] for idx in indices[0]]

    # Cross-encoder rerank
    pairs = [(query, doc["text"]) for doc in candidates]
    scores = reranker.predict(pairs)

    ranked = sorted(
        zip(scores, candidates),
        key=lambda x: x[0],
        reverse=True
    )

    return [
        {
            "score": float(score),
            "disease": doc["metadata"]["disease"],
            "samples": doc["metadata"]["num_samples"],
            "type": "symptom_to_disease"
        }
        for score, doc in ranked
    ]


# =========================
# Search: Disease â†’ Symptoms (New)
# =========================
def search_symptoms_from_disease(query: str, disease_map: Dict) -> List[Dict]:
    """
    TÃ¬m triá»‡u chá»©ng tá»« tÃªn bá»‡nh
    """
    query_lower = query.lower()
    
    # Extract disease name from query
    disease_name = None
    for disease in disease_map.keys():
        if disease.lower() in query_lower:
            disease_name = disease
            break
    
    # If not found, fuzzy match
    if not disease_name:
        # Simple fuzzy matching
        for disease in disease_map.keys():
            # Check if any word in query matches disease name
            query_words = set(query_lower.split())
            disease_words = set(disease.lower().split())
            
            if query_words & disease_words:
                disease_name = disease
                break
    
    if disease_name and disease_name in disease_map:
        data = disease_map[disease_name]
        return [{
            "disease": disease_name,
            "symptoms": data["symptoms"],
            "symptom_count": data["symptom_count"],
            "sample_questions": data["sample_questions"],
            "total_questions": data["question_count"],
            "type": "disease_to_symptom"
        }]
    
    # If still not found, return similar diseases
    results = []
    query_words = set(query_lower.split())
    
    for disease, data in disease_map.items():
        disease_words = set(disease.lower().split())
        overlap = len(query_words & disease_words)
        
        if overlap > 0:
            results.append({
                "disease": disease,
                "symptoms": data["symptoms"][:10],  # Limit to 10 symptoms
                "symptom_count": data["symptom_count"],
                "match_score": overlap / max(len(query_words), len(disease_words)),
                "type": "disease_to_symptom_fuzzy"
            })
    
    results.sort(key=lambda x: x["match_score"], reverse=True)
    return results[:5]  # Return top 5 matches


# =========================
# Unified Bidirectional Search
# =========================
def search_bidirectional(query: str, embed_model, reranker, index, documents, 
                        query_type: str = None, disease_map: Dict = None, top_k=TOP_K) -> List[Dict]:
    """
    TÃ¬m kiáº¿m hai chiá»u
    Args:
        query: Query string
        query_type: "symptoms_to_disease" or "disease_to_symptoms" (optional, will auto-detect if None)
        disease_map: Disease mapping dict (optional, will build if None)
    Returns: List of results
    """
    # Auto-detect direction if not specified
    if query_type is None:
        direction = detect_query_direction(query)
    else:
        # Convert from deploy.py format to internal format
        if query_type == "disease_to_symptoms":
            direction = "disease_to_symptom"
        else:
            direction = "symptom_to_disease"
    
    # Build disease_map if not provided
    if disease_map is None and direction == "disease_to_symptom":
        disease_map = build_disease_symptom_mapping(CSV_PATH)
    
    if direction == "disease_to_symptom":
        results = search_symptoms_from_disease(query, disease_map)
        # Format results to match expected output
        formatted_results = []
        for r in results:
            # Get first disease match
            formatted_results = [
                {"symptom": symptom, "disease": r["disease"], "score": r.get("match_score", 1.0)}
                for symptom in r["symptoms"]
            ]
            break  # Only use first match
        return formatted_results
    else:
        results = search_disease_from_symptoms(query, embed_model, reranker, 
                                              index, documents, top_k)
        return results


def search_bidirectional_legacy(query: str, embed_model, reranker, index, documents, 
                        disease_map: Dict, top_k=TOP_K) -> Tuple[str, List[Dict]]:
    """
    Legacy version that returns (direction, results)
    """
    direction = detect_query_direction(query)
    
    if direction == "disease_to_symptom":
        results = search_symptoms_from_disease(query, disease_map)
    else:
        results = search_disease_from_symptoms(query, embed_model, reranker, 
                                              index, documents, top_k)
    
    return direction, results


# =========================
# Format output
# =========================
def format_results(direction: str, results: List[Dict]) -> str:
    """
    Format káº¿t quáº£ theo hÆ°á»›ng truy váº¥n
    """
    output = []
    
    if direction == "disease_to_symptom":
        if not results:
            return "âŒ KhÃ´ng tÃ¬m tháº¥y bá»‡nh nÃ y trong cÆ¡ sá»Ÿ dá»¯ liá»‡u."
        
        for i, r in enumerate(results, 1):
            output.append(f"\n{'='*60}")
            output.append(f"ğŸ¥ Bá»‡nh: {r['disease']}")
            output.append(f"ğŸ“‹ Sá»‘ lÆ°á»£ng triá»‡u chá»©ng: {r['symptom_count']}")
            
            if "match_score" in r:
                output.append(f"ğŸ¯ Äá»™ khá»›p: {r['match_score']:.2%}")
            
            output.append(f"\nğŸ’Š CÃ¡c triá»‡u chá»©ng chÃ­nh:")
            for j, symptom in enumerate(r['symptoms'][:15], 1):
                output.append(f"   {j}. {symptom}")
            
            if len(r['symptoms']) > 15:
                output.append(f"   ... vÃ  {len(r['symptoms']) - 15} triá»‡u chá»©ng khÃ¡c")
            
            if "sample_questions" in r:
                output.append(f"\nğŸ“ VÃ­ dá»¥ cÃ¢u há»i tá»« bá»‡nh nhÃ¢n:")
                for j, q in enumerate(r['sample_questions'][:3], 1):
                    output.append(f"   {j}. {q[:80]}...")
    
    else:  # symptom_to_disease
        output.append(f"\n{'='*60}")
        output.append("ğŸ” Káº¾T QUáº¢ TÃŒM KIáº¾M Bá»†NH Tá»ª TRIá»†U CHá»¨NG")
        output.append(f"{'='*60}")
        
        for i, r in enumerate(results[:10], 1):
            output.append(f"\n{i}. ğŸ¥ {r['disease']}")
            output.append(f"   ğŸ“Š Äá»™ khá»›p: {r['score']:.4f}")
            output.append(f"   ğŸ“‹ Sá»‘ máº«u: {r['samples']}")
    
    return "\n".join(output)


# =========================
# DEMO
# =========================
if __name__ == "__main__":
    print("ğŸš€ Loading Bidirectional Retrieval System...")
    
    # Load models and data
    _, documents, index = load_assets()
    embed_model, reranker = load_models()
    
    print("\nğŸ“Š Building disease â†’ symptom mapping...")
    disease_map = build_disease_symptom_mapping()
    print(f"   âœ… Loaded {len(disease_map)} diseases")
    
    print("\n" + "="*70)
    print("ğŸ’¬ BIDIRECTIONAL HEALTH CHATBOT")
    print("="*70)
    
    # Example 1: Symptoms â†’ Disease
    print("\n" + "="*70)
    print("ğŸ“ EXAMPLE 1: TÃŒM Bá»†NH Tá»ª TRIá»†U CHá»¨NG")
    print("="*70)
    
    query1 = """
    TÃ´i hiá»‡n Ä‘ang cÃ³ cÃ¡c triá»‡u chá»©ng nhÆ° rá»¥ng tÃ³c,
    da sáº¡m mÃ u vÃ  kinh nguyá»‡t thÆ°a dáº§n.
    TÃ´i cÃ³ thá»ƒ Ä‘ang bá»‹ bá»‡nh gÃ¬?
    """
    
    print(f"\nâ“ Query: {query1.strip()}")
    direction, results = search_bidirectional(query1, embed_model, reranker, 
                                             index, documents, disease_map)
    print(f"\nğŸ¯ Detected direction: {direction}")
    print(format_results(direction, results))
    
    # Example 2: Disease â†’ Symptoms  
    print("\n\n" + "="*70)
    print("ğŸ“ EXAMPLE 2: TÃŒM TRIá»†U CHá»¨NG Tá»ª Bá»†NH")
    print("="*70)
    
    query2 = "Bá»‡nh Alzheimer cÃ³ triá»‡u chá»©ng gÃ¬?"
    
    print(f"\nâ“ Query: {query2}")
    direction, results = search_bidirectional(query2, embed_model, reranker, 
                                             index, documents, disease_map)
    print(f"\nğŸ¯ Detected direction: {direction}")
    print(format_results(direction, results))
    
    # Example 3: Another disease query
    print("\n\n" + "="*70)
    print("ğŸ“ EXAMPLE 3: TÃŒM TRIá»†U CHá»¨NG Tá»ª Bá»†NH KHÃC")
    print("="*70)
    
    query3 = "Triá»‡u chá»©ng cá»§a bá»‡nh tiá»ƒu Ä‘Æ°á»ng"
    
    print(f"\nâ“ Query: {query3}")
    direction, results = search_bidirectional(query3, embed_model, reranker, 
                                             index, documents, disease_map)
    print(f"\nğŸ¯ Detected direction: {direction}")
    print(format_results(direction, results))
    
    print("\n" + "="*70)
    print("âœ¨ Demo complete! System supports both directions.")
    print("="*70)
